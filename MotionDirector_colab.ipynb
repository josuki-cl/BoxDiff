{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josuki-cl/BoxDiff/blob/master/MotionDirector_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bcec82-2cce-49de-febd-83a1929c7b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MotionDirector'...\n",
            "remote: Enumerating objects: 206, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 206 (delta 48), reused 42 (delta 42), pack-reused 149 (from 1)\u001b[K\n",
            "Receiving objects: 100% (206/206), 139.84 MiB | 23.59 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n",
            "Cloning into '/content/MotionDirector/models/MotionDirector'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 71 (delta 4), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (71/71), 540.11 KiB | 5.05 MiB/s, done.\n",
            "Filtering content: 100% (15/15), 3.90 GiB | 40.85 MiB/s, done.\n",
            "/content/MotionDirector\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/MotionDirector\n",
        "!git clone https://huggingface.co/vdo/MotionDirector /content/MotionDirector/models/MotionDirector\n",
        "%cd /content/MotionDirector\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r lora.txt"
      ],
      "metadata": {
        "id": "R0mOfQdy814y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd lora  # 进入克隆的仓库目录\n",
        "!git checkout bdd51b04c49fa90a88919a19850ec3b4cf3c5ecd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi8Ly5-x8Qnp",
        "outputId": "951c6573-1f07-4e58-8299-2d9d533a2c43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: reference is not a tree: bdd51b04c49fa90a88919a19850ec3b4cf3c5ecd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cloneofsimo/lora.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTnA1VvA9MOc",
        "outputId": "2f7f2dd2-23f1-4fc6-b977-6d7ad222ae33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lora'...\n",
            "remote: Enumerating objects: 937, done.\u001b[K\n",
            "remote: Counting objects: 100% (437/437), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 937 (delta 371), reused 307 (delta 307), pack-reused 500 (from 1)\u001b[K\n",
            "Receiving objects: 100% (937/937), 182.96 MiB | 25.51 MiB/s, done.\n",
            "Resolving deltas: 100% (559/559), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n",
        "!pip install -q xformers==0.0.20"
      ],
      "metadata": {
        "id": "GytrjeV8hS0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahsezBnOG_uL",
        "outputId": "7519e56d-87a9-4396-8dde-3fbe2b22eddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-25 11:15:43,861] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-11-25 11:15:45.944024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 11:15:45.964403: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 11:15:45.970572: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 11:15:47.202675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing the conversion map\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m350\u001b[0m in \u001b[92m<module>\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m347 \u001b[0m\u001b[2m│   │   \u001b[0mlatents_path=latents_path,                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m348 \u001b[0m\u001b[2m│   │   \u001b[0mnoise_prior=args.noise_prior,                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m349 \u001b[0m\u001b[2m│   │   \u001b[0mrepeat_num=args.repeat_num,                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m350 \u001b[2m│   │   \u001b[0mtoken_indices=token_indices,                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   \u001b[0mbboxes=bboxes,                                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   \u001b[0mmax_guidance_iter=args.max_guidance_iter,                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   \u001b[0mmax_guidance_iter_per_step=args.max_guidance_iter_per_step,                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'token_indices'\u001b[0m is not defined\n"
          ]
        }
      ],
      "source": [
        "prompt = \"A person is riding a bicycle past the Eiffel Tower.\"\n",
        "prompt = f\"\\\"{prompt}\\\"\"\n",
        "negative_prompt = \"blurry\"\n",
        "negative_prompt = f\"\\\"{negative_prompt}\\\"\"\n",
        "\n",
        "width = 256\n",
        "height = 256\n",
        "num_frames = 24\n",
        "num_steps = 50\n",
        "guidance_scale = 15\n",
        "\n",
        "model = \"/content/MotionDirector/models/MotionDirector/zeroscope_v2_576w\"\n",
        "checkpoint_folder = \"/content/MotionDirector/models/MotionDirector/train/train_2023-12-02T13-39-36\"\n",
        "checkpoint_index = 300\n",
        "noise_prior = 0\n",
        "seed = 0\n",
        "!python MotionDirector_inference.py --model {model} --prompt {prompt} \\\n",
        "          --checkpoint_folder {checkpoint_folder} --checkpoint_index \\\n",
        "          {checkpoint_index} --noise_prior {noise_prior} --seed {seed} \\\n",
        "          --width {width} --height {height} --num-frames {num_frames} \\\n",
        "          --num-steps {num_steps} --guidance-scale {guidance_scale} \\\n",
        "          --xformers --negative-prompt {negative_prompt}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A person is riding a bicycle past the Eiffel Tower.\"\n",
        "prompt = f\"\\\"{prompt}\\\"\"\n",
        "negative_prompt = \"blurry\"\n",
        "negative_prompt = f\"\\\"{negative_prompt}\\\"\"\n",
        "\n",
        "width = 256\n",
        "height = 256\n",
        "num_frames = 24\n",
        "num_steps = 50\n",
        "guidance_scale = 15\n",
        "\n",
        "model = \"/content/MotionDirector/models/MotionDirector/zeroscope_v2_576w\"\n",
        "checkpoint_folder = \"/content/MotionDirector/models/MotionDirector/train/train_2023-12-02T13-39-36\"\n",
        "checkpoint_index = 300\n",
        "noise_prior = 0\n",
        "seed = 0\n",
        "!python MotionDirector_inference.py --model {model} --prompt {prompt} \\\n",
        "          --width {width} --height {height} --num-frames {num_frames} \\\n",
        "          --num-steps {num_steps} --checkpoint_folder {checkpoint_folder} \\\n",
        "          --checkpoint_index {checkpoint_index} --seed {seed} \\\n",
        "          --token_indices \"2,6;9,10\" --bboxes \"0.3,0.3,0.5,0.7;0.2,0.6,0.9,0.8\" \\\n",
        "          --max_guidance_iter 10 --max_guidance_iter_per_step 5 --scale_factor 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9Zipd3s-9rj",
        "outputId": "c8cff869-5ad7-41ff-f9f5-04ef4121903d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-25 11:26:06,293] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-11-25 11:26:08.893387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 11:26:08.913486: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 11:26:08.919588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 11:26:10.252241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing the conversion map\n",
            "\n",
            "解析布局引导参数:\n",
            "token_indices: [[2, 6], [9, 10]]\n",
            "bboxes: [[0.3, 0.3, 0.5, 0.7], [0.2, 0.6, 0.9, 0.8]]\n",
            "\n",
            "=== 进入 inference 函数 ===\n",
            "初始化 pipeline\n",
            "Lora successfully injected into UNet3DConditionModel.\n",
            "\n",
            "=== 开始第 1/1 次生成 ===\n",
            "准备输入潜在变量\n",
            "调用 pipeline\n",
            "\n",
            "准备传入的布局参数:\n",
            "token_indices: [[2, 6], [9, 10]]\n",
            "bboxes: [[0.3, 0.3, 0.5, 0.7], [0.2, 0.6, 0.9, 0.8]]\n",
            "max_guidance_iter: 10\n",
            "max_guidance_iter_per_step: 5\n",
            "scale_factor: 50\n",
            "\n",
            "=== 布局引导参数 ===\n",
            "token_indices: [[2, 6], [9, 10]]\n",
            "bboxes: [[0.3, 0.3, 0.5, 0.7], [0.2, 0.6, 0.9, 0.8]]\n",
            "max_guidance_iter: 10\n",
            "max_guidance_iter_per_step: 5\n",
            "scale_factor: 50\n",
            "batch_size: 1\n",
            "\n",
            "=== 开始布局优化 ===\n",
            "处 2 个对象的布局\n",
            "对象 1:\n",
            "- token索引: [2, 6]\n",
            "- 边界框: [0.3, 0.3, 0.5, 0.7]\n",
            "对象 2:\n",
            "- token索引: [9, 10]\n",
            "- 边界框: [0.2, 0.6, 0.9, 0.8]\n",
            "优化迭代出错: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.75 GiB total capacity; 14.13 GiB already allocated; 17.06 MiB free; 14.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "优化迭代出错: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.75 GiB total capacity; 14.13 GiB already allocated; 15.06 MiB free; 14.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "优化迭代出错: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.75 GiB total capacity; 14.13 GiB already allocated; 15.06 MiB free; 14.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "优化迭代出错: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.75 GiB total capacity; 14.13 GiB already allocated; 15.06 MiB free; 14.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "优化迭代出错: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 14.75 GiB total capacity; 14.13 GiB already allocated; 15.06 MiB free; 14.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "pipeline 执行出错: CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 14.75 GiB total capacity; 12.93 GiB already allocated; 1.51 GiB free; 13.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MotionDirector/MotionDirector_inference.py\", line 201, in inference\n",
            "    result = pipe(\n",
            "  File \"/content/MotionDirector/layout_guided_cogvideo_pipeline.py\", line 586, in __call__\n",
            "    noise_pred = self.unet(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/MotionDirector/layout_guided_cogvideo_pipeline.py\", line 219, in wrapped_forward\n",
            "    result = original_forward(*args, **kwargs)\n",
            "  File \"/content/MotionDirector/models/unet_3d_condition.py\", line 411, in forward\n",
            "    sample = self.transformer_in(sample, num_frames=num_frames).sample\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/transformer_temporal.py\", line 149, in forward\n",
            "    hidden_states = self.norm(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\", line 273, in forward\n",
            "    return F.group_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2530, in group_norm\n",
            "    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.75 GiB (GPU 0; 14.75 GiB total capacity; 12.93 GiB already allocated; 1.51 GiB free; 13.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "\n",
            "准备保存视频\n",
            "输出路径: ./outputs/inference/A_person_is_riding_a_bicycle_past_the_Eiffel_Tower_0.mp4\n",
            "保存视频时出错: local variable 'result' referenced before assignment\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MotionDirector/MotionDirector_inference.py\", line 235, in inference\n",
            "    if not result.frames:\n",
            "UnboundLocalError: local variable 'result' referenced before assignment\n",
            "=== inference 函数执行完成 ===\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m331\u001b[0m in \u001b[92m<module>\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbboxes: \u001b[0m\u001b[33m{\u001b[0mbboxes\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# 调用带布局引导的推理\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m331 \u001b[2m│   \u001b[0mvideo_frames = inference(                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m332 \u001b[0m\u001b[2m│   │   \u001b[0mmodel=args.model,                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0mprompt=args.prompt,                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0mnegative_prompt=args.negative_prompt,                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m254\u001b[0m in \u001b[92minference\u001b[0m                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   \u001b[0mtorch.cuda.empty_cache()                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33m=== inference 函数执行完成 ===\u001b[0m\u001b[33m\"\u001b[0m)                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m254 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m result.frames                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m255 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mUnboundLocalError: \u001b[0mlocal variable \u001b[32m'result'\u001b[0m referenced before assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oGMCUyDybSWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python MotionDirector_inference.py --model \"./models/zeroscope_v2_576w\" --prompt \"A person is riding a bicycle past the Eiffel Tower.\" --width 256 --height 256 --num-frames 12 --fps 8 --num-steps 30 --checkpoint_folder \"./outputs/train/riding_bicycle/\" --checkpoint_index 300 --noise_prior 0. --seed 7192280 --token_indices \"2,6;9,10\" --bboxes \"0.3,0.3,0.5,0.7;0.2,0.6,0.9,0.8\" --max_guidance_iter 10 --max_guidance_iter_per_step 5 --scale_factor 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUE0nWclMwo7",
        "outputId": "c9eec30b-b542-4912-fc52-b238f24cee21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-25 10:59:43,736] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-11-25 10:59:45.756330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 10:59:45.775733: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 10:59:45.781691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 10:59:47.016257: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing the conversion map\n",
            "\n",
            "解析布局引导参数:\n",
            "token_indices: [[2, 6], [9, 10]]\n",
            "bboxes: [[0.3, 0.3, 0.5, 0.7], [0.2, 0.6, 0.9, 0.8]]\n",
            "\n",
            "=== 进入 inference 函数 ===\n",
            "初始化 pipeline\n",
            "Lora successfully injected into UNet3DConditionModel.\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m331\u001b[0m in \u001b[92m<module>\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbboxes: \u001b[0m\u001b[33m{\u001b[0mbboxes\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m329 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m330 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# 调用带布局引导的推理\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m331 \u001b[2m│   \u001b[0mvideo_frames = inference(                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m332 \u001b[0m\u001b[2m│   │   \u001b[0mmodel=args.model,                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m333 \u001b[0m\u001b[2m│   │   \u001b[0mprompt=args.prompt,                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m334 \u001b[0m\u001b[2m│   │   \u001b[0mnegative_prompt=args.negative_prompt,                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m168\u001b[0m in \u001b[92minference\u001b[0m                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.autocast(device, dtype=torch.half):                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33m初始化 pipeline\u001b[0m\u001b[33m\"\u001b[0m)                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m168 \u001b[2m│   │   \u001b[0mpipe = initialize_pipeline(model, device, xformers, sdp, lora_path, lora_rank, l   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(repeat_num):                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m171 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m=== 开始第 \u001b[0m\u001b[33m{\u001b[0mi+\u001b[94m1\u001b[0m\u001b[33m}\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{\u001b[0mrepeat_num\u001b[33m}\u001b[0m\u001b[33m 次生成 ===\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/MotionDirector/\u001b[0m\u001b[1;33mMotionDirector_inference.py\u001b[0m:\u001b[94m62\u001b[0m in \u001b[92minitialize_pipeline\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   \u001b[0mtext_encoder.eval()                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   \u001b[0munet_and_text_g_c(unet, text_encoder, \u001b[94mFalse\u001b[0m, \u001b[94mFalse\u001b[0m)                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 62 \u001b[2m│   \u001b[0mpipe = LayoutGuidedCogVideoXPipeline.from_pretrained(                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   \u001b[0mpretrained_model_name_or_path=\u001b[33m\"\u001b[0m\u001b[33m./models/zeroscope_v2_576w\u001b[0m\u001b[33m\"\u001b[0m,                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   \u001b[0mscheduler=scheduler,                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0mtokenizer=tokenizer,                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m882\u001b[0m in             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 879 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 1. Download the checkpoints and configs\u001b[0m                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 880 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# use snapshot download here to get it working from from_pretrained\u001b[0m               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 881 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m os.path.isdir(pretrained_model_name_or_path):                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 882 \u001b[2m│   │   │   \u001b[0mcached_folder = \u001b[96mcls\u001b[0m.download(                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 883 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path,                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 884 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcache_dir=cache_dir,                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 885 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mresume_download=resume_download,                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m1185\u001b[0m in \u001b[92mdownload\u001b[0m   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1182 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1183 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1184 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1185 \u001b[2m│   │   │   │   \u001b[0minfo = model_info(                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1186 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1187 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0muse_auth_token=use_auth_token,                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1188 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mrevision=revision,                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m110\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m110 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m158\u001b[0m in              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mvalidate_repo_id\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be a string, not \u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(repo_id)\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m repo_id.count(\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m\"\u001b[0m) > \u001b[94m1\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be in the form \u001b[0m\u001b[33m'\u001b[0m\u001b[33mrepo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m or \u001b[0m\u001b[33m'\u001b[0m\u001b[33mnamespace/repo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. Use `repo_type` argument if needed.\u001b[0m\u001b[33m\"\u001b[0m                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mHFValidationError: \u001b[0mRepo id must be in the form \u001b[32m'repo_name'\u001b[0m or \u001b[32m'namespace/repo_name'\u001b[0m: \n",
            "\u001b[32m'./models/zeroscope_v2_576w'\u001b[0m. Use `repo_type` argument if needed.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"jax[cuda12_local]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myFKwTKQ6ea_",
        "outputId": "24146f25-ddeb-4357-9491-1cf3796d5921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax==0.4.23 (from jax[cuda12_local]==0.4.23)\n",
            "  Downloading jax-0.4.23-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (1.24.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax==0.4.23->jax[cuda12_local]==0.4.23) (1.13.1)\n",
            "Collecting jaxlib==0.4.23+cuda12.cudnn89 (from jax[cuda12_local]==0.4.23)\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23%2Bcuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl (131.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.23+cuda12.cudnn89 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.24.0 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.23 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.23+cuda12.cudnn89 which is incompatible.\n",
            "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.23 jaxlib-0.4.23+cuda12.cudnn89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Q7ue39OF3R",
        "outputId": "9954a831-175b-4b1f-8043-a1246dada50a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}